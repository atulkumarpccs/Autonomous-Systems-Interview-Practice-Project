# Autonomous-Systems-Interview-Practice-Project

## Perception/Sensor Engineer


So, you're interested in a role as a Perception/Sensor Engineer? Great choice! Below, you will find one general question, as well as a list of Perception/Sensor Engineer-specific questions. To complete the project, you'll need to complete the general question along with three questions from the role-specific list, with at least one of them needing to be marked as requiring code with [Code]. While it isn't required to use code in the other two, we highly encourage you to either code, diagram or draw any relevant information for your answers in the other questions as well.

Make sure not to just select questions in areas you are most comfortable with! You likely won't get so lucky in a real interview situation.


## Required question
Explain a recent project you've worked on. Why did you choose this project? What difficulties did you run into this project that you did not expect, and how did you solve them?

Perception/Sensor Engineer questions
Pick three of these questions, including at least one marked [Code].

* Explain your lane detection algorithm. How can it be improved? How does it account for curves and hills? How could you integrate machine learning techniques into the algorithm?
* What are some of the advantages & disadvantages of cameras, lidar and radar? What combination of these (and other sensors) would you use to ensure appropriate and accurate perception of the environment?
* How do features from algorithms like SIFT, SURF and HOG differ? Explain how these algorithms work, and how you would use them within a perception pipeline.
* Explain the technique behind Hough Transforms. Where would this type of feature extraction be useful?
[Code] What is the RANSAC algorithm? Code the steps that this algorithm takes to help deal with outliers in data. How can we use this algorithm for computer vision?
* Describe the overall process of how a basic Kalman Filter works. Where might a basic Kalman Filter be less than sufficient? How can you improve the basic algorithm to improve performance in such a situation?
* How does an Extended Kalman Filter differ from a regular Kalman Filter? Provide an example of where an EKF would be necessary or an improvement, and detail why it would be needed in that situation.
* What is the difference between an Extended Kalman Filter and an Unscented Kalman Filter? In what situations would there be larger differences between the two approaches?
* [Code] Explain the steps behind how an Extended Kalman Filter is implemented.
* Have you worked with point clouds and/or the Point Cloud Library (PCL) before? If youâ€™ve used PCL before, which modules of PCL did you use, and what application did you use it toward?
* [Code] Describe how a particle filter works, where it is useful, and how it performs against similar algorithms. Code an example of how you update the weights of the particles between steps.
* Your perception subsystem has noticed an object in the path of your robot, but it has failed to determine what the object is. How would your perception subsystem further handle this situation?
* [Code] What approach would you take if the various sensors you are using have different refresh rates?
* [Code] 3D point clouds are sometimes processed into "voxels" as one step into object detection. 1) What is a voxel, 2) What is the process behind converting point cloud data into voxels (code this), and 3) Why would we want to perform this step with our point cloud data?

## Relevant Nanodegree Projects

If you put these on your resume, make sure you know your code and the topic in-depth before the interview!

Self-Driving Car Engineer - Finding Lane Lines, Advanced Lane Finding, Vehicle Detection and Tracking, Extended Kalman Filters, Unscented Kalman Filters, along with perception-based deep learning projects

## Acceptence Criteria

https://review.udacity.com/#!/rubrics/2285/view
